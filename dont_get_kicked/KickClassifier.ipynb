{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_onehot(df, cols):\n",
    "    \"\"\"\n",
    "    One-hot encoding is applied to columns specified in a pandas DataFrame.\n",
    "    \n",
    "    Modified from: https://gist.github.com/kljensen/5452382\n",
    "    \n",
    "    Details:\n",
    "    \n",
    "    http://en.wikipedia.org/wiki/One-hot\n",
    "    http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n",
    "    \n",
    "    @param df pandas DataFrame\n",
    "    @param cols a list of columns to encode\n",
    "    @return a DataFrame with one-hot encoding\n",
    "    \"\"\"\n",
    "    vec = DictVectorizer()\n",
    "    \n",
    "    vec_data = pd.DataFrame(vec.fit_transform(df[cols].to_dict(orient='records')).toarray())\n",
    "    vec_data.columns = vec.get_feature_names()\n",
    "    vec_data.index = df.index\n",
    "    \n",
    "    df = df.drop(cols, axis=1)\n",
    "    df = df.join(vec_data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "df = pd.read_csv('training.csv')\n",
    "\n",
    "# Shuffle data (rows)\n",
    "df = df.iloc[np.random.permutation(len(df))]\n",
    "\n",
    "df = df.head(30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IsBadBuy\n",
      "0    26369\n",
      "1     3631\n",
      "Name: RefId, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Explore columns\n",
    "#len(df.SubModel.unique())\n",
    "#print df.AUCGUART.isnull().sum()\n",
    "#print df.PRIMEUNIT.isnull().sum()\n",
    "print df.groupby('IsBadBuy').count()['RefId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "cols_to_drop = ['RefId', 'PurchDate']#, 'Color', 'WheelTypeID', 'PRIMEUNIT', 'AUCGUART'] \n",
    "df = df.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get labels\n",
    "Y = df['IsBadBuy'].values.tolist()\n",
    "df = df.drop('IsBadBuy', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalize and pre-process data\n",
    "df1 = df.select_dtypes(include=['int64', 'float64'])\n",
    "df2 = df.select_dtypes(exclude=['int64', 'float64'])\n",
    "\n",
    "df1_norm = (df1 - df1.min()) / (df1.max() - df1.min())\n",
    "\n",
    "df2_onehot = encode_onehot(df2, df2.columns)\n",
    "\n",
    "frames = [df1_norm, df2_onehot]\n",
    "X = pd.concat(frames, axis = 1)\n",
    "X = X.values\n",
    "X = Imputer().fit_transform(X)\n",
    "X = X.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training/testing split\n",
    "split = 20000\n",
    "X_train = X[:split]\n",
    "X_test = X[split:]\n",
    "Y_train = Y[:split]\n",
    "Y_test = Y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clf = DecisionTreeClassifier()\n",
    "#clf = clf.fit(X_train, Y_train)\n",
    "\n",
    "#clf = LogisticRegression()\n",
    "#clf = clf.fit(X_train, Y_train)\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf = clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_predict = clf.predict(X_test)\n",
    "Y_predict = Y_predict.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 1259\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-72456af2c058>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mtp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrong\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mprecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "wrong = 0\n",
    "tp = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "\n",
    "for idx, pred in enumerate(Y_predict):\n",
    "    if pred == 1 and Y_test[idx] == 1:\n",
    "        tp += 1\n",
    "    if pred == 1 and Y_test[idx] == 0:\n",
    "        fp += 1\n",
    "    if pred == 0 and Y_test[idx] == 1:\n",
    "        fn += 1\n",
    "    if pred != Y_test[idx]:\n",
    "        wrong += 1\n",
    "   \n",
    "print tp, fp, fn\n",
    "err = wrong*1.0/len(Y_test)\n",
    "precision = tp*1.0/(tp+fp)\n",
    "recall = tp*1.0/(tp+fn)\n",
    "\n",
    "print tp, fp, fn\n",
    "print err, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('dummy.csv')\n",
    "df = df.corr()[['X1']]\n",
    "df = df.sort_values(['X1'], 0, False)\n",
    "df.to_csv('dummy_out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.linear_model.logistic.LogisticRegression"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
